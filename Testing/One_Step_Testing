{"cells":[{"cell_type":"markdown","source":["# **ONE-STEP DETECTION MODULE**\n"],"metadata":{"id":"9-HE3s1t7Rj1"}},{"cell_type":"markdown","metadata":{"id":"qT8zgQp5O0Pj"},"source":["#Install Required Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pC1Z94WiY0Mk"},"outputs":[],"source":["!pip install -q pillow lxml jupyter matplotlib cython pandas contextlib2\n","!apt-get install -qq protobuf-compiler\n","!pip install -q pycocotools tf_slim"]},{"cell_type":"markdown","metadata":{"id":"kqFX4hlPK_WH"},"source":["#Set Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyDnMzl8LH65"},"outputs":[],"source":["import os\n","# Repo URL\n","repo_url = 'https://github.com/moreyball/Automated-Fall-Detection'\n","\n","# Models\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n","        'model_path': '/models/ssd_mobilenet_v2/',\n","        'pipeline_file': 'pipeline.config'\n","}\n","}\n","# Select a model to use.\n","selected_model = 'ssd_mobilenet_v2'\n","\n","model_name = MODELS_CONFIG[selected_model]['model_name']\n","model_path = MODELS_CONFIG[selected_model]['model_path']\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Set Repository Home Directory\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","# Set Label Map (.pbtxt) path and pipeline.config path\n","label_map_pbtxt_fname = repo_dir_path + '/annotations/fall_detection_label_map.pbtxt'\n","pipeline_fname = repo_dir_path + model_path + pipeline_file\n","\n","# Set .record path\n","test_record_fname = repo_dir_path + '/annotations/test.record'\n","train_record_fname = repo_dir_path + '/annotations/train.record'\n","\n","# Set output directories and clean up\n","model_dir = repo_dir_path + '/training/'\n","output_dir = repo_dir_path + '/exported-models/'\n","\n","!rm -rf {model_dir} {output_dir}\n","os.makedirs(model_dir, exist_ok=True)\n","os.makedirs(output_dir, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"kPZhPF0yLD-c"},"source":["#Clone Tensorflow models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17363,"status":"ok","timestamp":1683596170153,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"oDL0xgpVACMu","outputId":"516fe7d0-9d50-4e2d-a779-24389325724d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","fatal: destination path 'models' already exists and is not an empty directory.\n","/content/models/research\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: avro-python3 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.2)\n","Requirement already satisfied: apache-beam in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.46.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (8.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.29.34)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.6.0.post1)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.6)\n","Requirement already satisfied: lvis in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.5.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n","Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.12.0)\n","Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.32.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.12.0)\n","Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.4.7)\n","Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.2.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.99)\n","Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.20.0)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.2)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.13.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: tensorflow-text~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.12.1)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.13)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n","Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.4)\n","Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n","Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.2.4)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.72)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.8.12)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.13.0)\n","Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.7.4)\n","Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n","Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.27.1)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n","Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n","Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.18)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: httplib2<0.22.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n","Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n","Requirement already satisfied: pyarrow<10.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.7.0.72)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.0.7)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.39.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (23.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.32.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.65.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (23.3.3)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.12.2)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.13.3)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.13.1)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.3)\n","Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.40.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.15.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.12.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.59.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697012 sha256=c2ef47602160de602e0d82d616d84e53a161c2096bfff9139b93a0fbfa142fbc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-cs9m7f2o/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n","Successfully built object-detection\n","Installing collected packages: object-detection\n","  Attempting uninstall: object-detection\n","    Found existing installation: object-detection 0.1\n","    Can't uninstall 'object-detection'. No files were found to uninstall.\n","Successfully installed object-detection-0.1\n","2023-05-09 01:36:02.289046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-09 01:36:03.342756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["# Clone Tensorflow model repo\n","%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","# Compile protocol buffers\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","!cp object_detection/packages/tf2/setup.py .\n","# Set environment variables\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models:/content/models/research/:/content/models/research/slim/'\n","# Install libraries\n","!pip install .\n","# Test\n","!python object_detection/builders/model_builder_test.py"]},{"cell_type":"markdown","metadata":{"id":"9n6_6dUhAG2O"},"source":["# COCO API Installation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6715,"status":"ok","timestamp":1683596176850,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"yOkiwKhDAFyl","outputId":"ba4a2731-dec9-4f61-f597-fc956456b0a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","fatal: destination path 'cocoapi' already exists and is not an empty directory.\n","/content/cocoapi/PythonAPI\n","python setup.py build_ext --inplace\n","running build_ext\n","skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n","building 'pycocotools._mask' extension\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.10/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I../common -I/usr/include/python3.10 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.10/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.10\n","creating build/lib.linux-x86_64-3.10/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC build/temp.linux-x86_64-3.10/../common/maskApi.o build/temp.linux-x86_64-3.10/pycocotools/_mask.o -o build/lib.linux-x86_64-3.10/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.10/pycocotools/_mask.cpython-310-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"]}],"source":["# Coco Installation (Optional, required when using Coco Evaluation)\n","%cd /content\n","!git clone --quiet https://github.com/cocodataset/cocoapi.git\n","%cd cocoapi/PythonAPI\n","!make\n","!cp -r pycocotools /content/models/research/"]},{"cell_type":"markdown","metadata":{"id":"Gt0tezrrJ_e3"},"source":["Download Pretrained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1574,"status":"ok","timestamp":1683596178415,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"ce7y7tmYJ_Qd","outputId":"aabf4313-7749-4de4-e585-d190bb276f3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n","/content/models/research/pretrained_model\n","total 24K\n","drwxr-x---  4 345018 89939 4.0K Jul 11  2020 .\n","drwxr-xr-x 26 root   root  4.0K May  9 01:36 ..\n","drwxr-x---  2 345018 89939 4.0K Jul 10  2020 checkpoint\n","-rw-r-----  1 345018 89939 4.4K Jul 11  2020 pipeline.config\n","drwxr-x---  3 345018 89939 4.0K Jul 10  2020 saved_model\n","fine_tune_checkpoint:  /content/models/research/pretrained_model/checkpoint/ckpt-0\n"]}],"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = model_name + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(model_name, DEST_DIR)\n","\n","# Check downloaded files\n","!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}\n","\n","# Set fine tune checkpoint\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"checkpoint/ckpt-0\")\n","print(\"fine_tune_checkpoint: \", fine_tune_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30286,"status":"ok","timestamp":1683596208688,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"61kEoJgBK2W_","outputId":"658c73b5-51d6-4b89-9d55-9ab2abe58a84"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'Automated-Fall-Detection'...\n","remote: Enumerating objects: 4209, done.\u001b[K\n","remote: Counting objects: 100% (801/801), done.\u001b[K\n","remote: Compressing objects: 100% (194/194), done.\u001b[K\n","remote: Total 4209 (delta 55), reused 686 (delta 15), pack-reused 3408\u001b[K\n","Receiving objects: 100% (4209/4209), 364.10 MiB | 14.31 MiB/s, done.\n","Resolving deltas: 100% (1110/1110), done.\n","Updating files: 100% (3151/3151), done.\n","/content/Automated-Fall-Detection\n","Already up to date.\n"]}],"source":["import os\n","%cd /content\n","# Clean up\n","!rm -rf {repo_dir_path}\n","\n","# Clone\n","!git clone -b Winston  {repo_url}\n","\n","# Pull (just in case the repo already exists)\n","%cd {repo_dir_path}\n","!git pull\n","\n","# Check if label map and pipeline files exist\n","assert os.path.isfile(label_map_pbtxt_fname), '`{}` not exist'.format(label_map_pbtxt_fname)\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":780,"status":"ok","timestamp":1683596209466,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"-8kwVmpsK4me","outputId":"9dfbd48c-3e6b-465b-8c12-950a01a1b676"},"outputs":[{"output_type":"stream","name":"stdout","text":["model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 3\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.97,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2_keras'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.97,\n","          epsilon: 0.001,\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.75,\n","          gamma: 2.0\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","          delta: 1.0\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 32\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  num_steps: 10000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: .8\n","          total_steps: 10000\n","          warmup_learning_rate: 0.13333\n","          warmup_steps: 2000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"annotations/fall_detection_label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"annotations/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","  num_examples:8\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"annotations/fall_detection_label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"annotations/test.record\"\n","  }\n","}\n"]}],"source":["# Check pipeline config - update if required\n","!cat {pipeline_fname}"]},{"cell_type":"markdown","metadata":{"id":"J0DsjSSk32jv"},"source":["#Image Processing"]},{"cell_type":"markdown","source":["Convert Yolo file to XML"],"metadata":{"id":"8JlU8V7mDKub"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683596209466,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"DGR09F-lNJ3V","outputId":"c77664f6-98cc-461d-8050-a2435e10d44d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Automated-Fall-Detection\n"]}],"source":["%cd {repo_dir_path}\n","\n","!python scripts/yolo_xml.py \n"]},{"cell_type":"markdown","source":["Convert xml files to CSV file"],"metadata":{"id":"VkfoewTQDPac"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1795,"status":"ok","timestamp":1683596211259,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"waUfA4GzNJt8","outputId":"28052d7c-3c4e-424a-bbcb-3b37282d1ce1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully converted xml to csv.\n","Successfully converted xml to csv.\n"]}],"source":["!python scripts/xml_to_csv.py -i images/train -o annotations/train_labels.csv\n","\n","!python scripts/xml_to_csv.py -i images/test -o annotations/test_labels.csv"]},{"cell_type":"markdown","source":[],"metadata":{"id":"LBsiPO2VDS08"}},{"cell_type":"markdown","source":["Generate tfrecord file from CSV"],"metadata":{"id":"ryso6gMmDWkc"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9581,"status":"ok","timestamp":1683596220837,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"5TH5a3ejNJj6","outputId":"5328f8e6-4414-4ea9-bcfe-4c4f34a361d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: annotations/train.record\n","Successfully created the CSV file: annotations/train_labels.csv\n","Successfully created the TFRecord file: annotations/test.record\n","Successfully created the CSV file: annotations/test_labels.csv\n"]}],"source":["# Create train data:\n","!python scripts/generate_tfrecord.py -c annotations/train_labels.csv -i images/train -x images/train -o annotations/train.record -l annotations/fall_detection_label_map.pbtxt\n","\n","# Create test data:\n","!python scripts/generate_tfrecord.py -c annotations/test_labels.csv -i images/test -x images/test -o annotations/test.record -l annotations/fall_detection_label_map.pbtxt\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GeQghCE-7EOl"},"source":["# Train\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1683596664154,"user":{"displayName":"Teck Ping Lim","userId":"16756498640581581868"},"user_tz":-480},"id":"ErbfjY4_7IQg","outputId":"b1c52d00-ed92-4491-a475-560101a2ae1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Automated-Fall-Detection\n","Already up to date.\n"]}],"source":["# # Make sure to have the latest project repo downloaded\n","%cd {repo_dir_path}\n","!git pull"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-apLZMo7Tzf","outputId":"ec169487-73cf-48be-b9d7-2078eb1c2147"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Automated-Fall-Detection\n","2023-05-09 01:44:28.136004: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-09 01:44:29.630083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-05-09 01:44:33.292384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:33.322601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:33.322918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:33.333569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:33.333853: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:33.334060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:35.761578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:35.761901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:35.762139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-09 01:44:35.762289: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-09 01:44:35.762332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13678 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0509 01:44:35.824413 140614079854400 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0509 01:44:35.827963 140614079854400 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0509 01:44:35.828107 140614079854400 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0509 01:44:36.013790 140614079854400 deprecation.py:364] From /content/models/research/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['annotations/train.record']\n","I0509 01:44:36.028342 140614079854400 dataset_builder.py:162] Reading unweighted datasets: ['annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['annotations/train.record']\n","I0509 01:44:36.028596 140614079854400 dataset_builder.py:79] Reading record datasets for input file: ['annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0509 01:44:36.028696 140614079854400 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0509 01:44:36.028795 140614079854400 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0509 01:44:36.047356 140614079854400 deprecation.py:364] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0509 01:44:36.071782 140614079854400 deprecation.py:364] From /content/models/research/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","2023-05-09 01:44:37.611451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n","\t [[{{node cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n","2023-05-09 01:44:37.611605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n","\t [[{{node cond/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n","2023-05-09 01:44:37.627332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n","\t [[{{node cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n","2023-05-09 01:44:37.627463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1' with dtype int64 and shape [1]\n","\t [[{{node cond_1/SparseToDense/ParseSingleExample/ParseExample/ParseExampleV2_1}}]]\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0509 01:44:42.393794 140614079854400 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0509 01:44:47.077524 140614079854400 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0509 01:44:50.782464 140614079854400 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\n","\n","W0509 01:44:52.955690 140614079854400 module_wrapper.py:149] From /content/models/research/object_detection/builders/optimizer_builder.py:124: The name tf.keras.optimizers.SGD is deprecated. Please use tf.keras.optimizers.legacy.SGD instead.\n","\n","2023-05-09 01:44:53.000795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_26' with dtype resource\n","\t [[{{node Placeholder/_26}}]]\n","2023-05-09 01:44:53.001470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_29' with dtype int64\n","\t [[{{node Placeholder/_29}}]]\n","/usr/local/lib/python3.10/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn(\n","I0509 01:45:00.202042 140609159747328 api.py:459] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0509 01:45:02.609930 140609159747328 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0509 01:45:02.610317 140609159747328 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0509 01:45:02.610545 140609159747328 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0509 01:45:02.610718 140609159747328 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0509 01:45:02.610878 140609159747328 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0509 01:45:02.611038 140609159747328 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n","I0509 01:45:15.260915 140609159747328 api.py:459] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n","2023-05-09 01:45:37.871147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n","2023-05-09 01:45:43.908975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n","\t [[{{node Placeholder/_0}}]]\n","2023-05-09 01:45:43.909979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_26' with dtype resource\n","\t [[{{node Placeholder/_26}}]]\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.183170 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.186259 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.187434 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.188382 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.191820 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.192758 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.193730 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.194723 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.199023 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0509 01:45:45.199994 140614079854400 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0509 01:45:46.292820 140609268475648 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","I0509 01:45:47.335171 140609268475648 api.py:459] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n","I0509 01:45:59.096539 140609268475648 api.py:459] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n","I0509 01:46:10.529868 140609268475648 api.py:459] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n","I0509 01:46:23.288029 140609268475648 api.py:459] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n","2023-05-09 01:46:45.816535: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146546688 exceeds 10% of free system memory.\n","2023-05-09 01:46:46.152875: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146546688 exceeds 10% of free system memory.\n","2023-05-09 01:46:48.156561: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146546688 exceeds 10% of free system memory.\n","2023-05-09 01:46:54.826442: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146546688 exceeds 10% of free system memory.\n","2023-05-09 01:46:56.869596: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 146546688 exceeds 10% of free system memory.\n","INFO:tensorflow:Step 100 per-step time 0.941s\n","I0509 01:47:20.080227 140614079854400 model_lib_v2.py:705] Step 100 per-step time 0.941s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5137546,\n"," 'Loss/localization_loss': 0.3127648,\n"," 'Loss/regularization_loss': 0.10235725,\n"," 'Loss/total_loss': 0.92887664,\n"," 'learning_rate': 0.1666635}\n","I0509 01:47:20.080683 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.5137546,\n"," 'Loss/localization_loss': 0.3127648,\n"," 'Loss/regularization_loss': 0.10235725,\n"," 'Loss/total_loss': 0.92887664,\n"," 'learning_rate': 0.1666635}\n","INFO:tensorflow:Step 200 per-step time 0.271s\n","I0509 01:47:47.208461 140614079854400 model_lib_v2.py:705] Step 200 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.45075113,\n"," 'Loss/localization_loss': 0.30174845,\n"," 'Loss/regularization_loss': 0.105952874,\n"," 'Loss/total_loss': 0.85845244,\n"," 'learning_rate': 0.19999701}\n","I0509 01:47:47.208862 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.45075113,\n"," 'Loss/localization_loss': 0.30174845,\n"," 'Loss/regularization_loss': 0.105952874,\n"," 'Loss/total_loss': 0.85845244,\n"," 'learning_rate': 0.19999701}\n","INFO:tensorflow:Step 300 per-step time 0.282s\n","I0509 01:48:15.443953 140614079854400 model_lib_v2.py:705] Step 300 per-step time 0.282s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3751295,\n"," 'Loss/localization_loss': 0.22130184,\n"," 'Loss/regularization_loss': 0.110401824,\n"," 'Loss/total_loss': 0.7068331,\n"," 'learning_rate': 0.23333052}\n","I0509 01:48:15.444389 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.3751295,\n"," 'Loss/localization_loss': 0.22130184,\n"," 'Loss/regularization_loss': 0.110401824,\n"," 'Loss/total_loss': 0.7068331,\n"," 'learning_rate': 0.23333052}\n","INFO:tensorflow:Step 400 per-step time 0.272s\n","I0509 01:48:42.647849 140614079854400 model_lib_v2.py:705] Step 400 per-step time 0.272s\n","INFO:tensorflow:{'Loss/classification_loss': 0.44376573,\n"," 'Loss/localization_loss': 0.24676149,\n"," 'Loss/regularization_loss': 0.11551206,\n"," 'Loss/total_loss': 0.8060393,\n"," 'learning_rate': 0.26666403}\n","I0509 01:48:42.649093 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.44376573,\n"," 'Loss/localization_loss': 0.24676149,\n"," 'Loss/regularization_loss': 0.11551206,\n"," 'Loss/total_loss': 0.8060393,\n"," 'learning_rate': 0.26666403}\n","INFO:tensorflow:Step 500 per-step time 0.272s\n","I0509 01:49:09.810114 140614079854400 model_lib_v2.py:705] Step 500 per-step time 0.272s\n","INFO:tensorflow:{'Loss/classification_loss': 0.43669,\n"," 'Loss/localization_loss': 0.19853564,\n"," 'Loss/regularization_loss': 0.12231163,\n"," 'Loss/total_loss': 0.7575373,\n"," 'learning_rate': 0.2999975}\n","I0509 01:49:09.810564 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.43669,\n"," 'Loss/localization_loss': 0.19853564,\n"," 'Loss/regularization_loss': 0.12231163,\n"," 'Loss/total_loss': 0.7575373,\n"," 'learning_rate': 0.2999975}\n","INFO:tensorflow:Step 600 per-step time 0.272s\n","I0509 01:49:36.961033 140614079854400 model_lib_v2.py:705] Step 600 per-step time 0.272s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3339461,\n"," 'Loss/localization_loss': 0.16784513,\n"," 'Loss/regularization_loss': 0.12752911,\n"," 'Loss/total_loss': 0.6293204,\n"," 'learning_rate': 0.33333102}\n","I0509 01:49:36.963160 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.3339461,\n"," 'Loss/localization_loss': 0.16784513,\n"," 'Loss/regularization_loss': 0.12752911,\n"," 'Loss/total_loss': 0.6293204,\n"," 'learning_rate': 0.33333102}\n","INFO:tensorflow:Step 700 per-step time 0.274s\n","I0509 01:50:04.336757 140614079854400 model_lib_v2.py:705] Step 700 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.33926326,\n"," 'Loss/localization_loss': 0.15311992,\n"," 'Loss/regularization_loss': 0.13358502,\n"," 'Loss/total_loss': 0.6259682,\n"," 'learning_rate': 0.36666453}\n","I0509 01:50:04.337158 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.33926326,\n"," 'Loss/localization_loss': 0.15311992,\n"," 'Loss/regularization_loss': 0.13358502,\n"," 'Loss/total_loss': 0.6259682,\n"," 'learning_rate': 0.36666453}\n","INFO:tensorflow:Step 800 per-step time 0.271s\n","I0509 01:50:31.456223 140614079854400 model_lib_v2.py:705] Step 800 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.34110418,\n"," 'Loss/localization_loss': 0.19183534,\n"," 'Loss/regularization_loss': 0.14020246,\n"," 'Loss/total_loss': 0.673142,\n"," 'learning_rate': 0.399998}\n","I0509 01:50:31.456577 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.34110418,\n"," 'Loss/localization_loss': 0.19183534,\n"," 'Loss/regularization_loss': 0.14020246,\n"," 'Loss/total_loss': 0.673142,\n"," 'learning_rate': 0.399998}\n","INFO:tensorflow:Step 900 per-step time 0.273s\n","I0509 01:50:58.770564 140614079854400 model_lib_v2.py:705] Step 900 per-step time 0.273s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3739736,\n"," 'Loss/localization_loss': 0.21666844,\n"," 'Loss/regularization_loss': 0.15121756,\n"," 'Loss/total_loss': 0.7418596,\n"," 'learning_rate': 0.4333315}\n","I0509 01:50:58.771449 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.3739736,\n"," 'Loss/localization_loss': 0.21666844,\n"," 'Loss/regularization_loss': 0.15121756,\n"," 'Loss/total_loss': 0.7418596,\n"," 'learning_rate': 0.4333315}\n","INFO:tensorflow:Step 1000 per-step time 0.274s\n","I0509 01:51:26.126948 140614079854400 model_lib_v2.py:705] Step 1000 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4209144,\n"," 'Loss/localization_loss': 0.2084167,\n"," 'Loss/regularization_loss': 0.1571536,\n"," 'Loss/total_loss': 0.7864847,\n"," 'learning_rate': 0.46666503}\n","I0509 01:51:26.127332 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.4209144,\n"," 'Loss/localization_loss': 0.2084167,\n"," 'Loss/regularization_loss': 0.1571536,\n"," 'Loss/total_loss': 0.7864847,\n"," 'learning_rate': 0.46666503}\n","INFO:tensorflow:Step 1100 per-step time 0.290s\n","I0509 01:51:55.167431 140614079854400 model_lib_v2.py:705] Step 1100 per-step time 0.290s\n","INFO:tensorflow:{'Loss/classification_loss': 0.31623873,\n"," 'Loss/localization_loss': 0.16781098,\n"," 'Loss/regularization_loss': 0.16199945,\n"," 'Loss/total_loss': 0.64604914,\n"," 'learning_rate': 0.4999985}\n","I0509 01:51:55.167913 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.31623873,\n"," 'Loss/localization_loss': 0.16781098,\n"," 'Loss/regularization_loss': 0.16199945,\n"," 'Loss/total_loss': 0.64604914,\n"," 'learning_rate': 0.4999985}\n","INFO:tensorflow:Step 1200 per-step time 0.274s\n","I0509 01:52:22.594600 140614079854400 model_lib_v2.py:705] Step 1200 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.36059764,\n"," 'Loss/localization_loss': 0.22189526,\n"," 'Loss/regularization_loss': 0.17509195,\n"," 'Loss/total_loss': 0.7575848,\n"," 'learning_rate': 0.53333205}\n","I0509 01:52:22.595005 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.36059764,\n"," 'Loss/localization_loss': 0.22189526,\n"," 'Loss/regularization_loss': 0.17509195,\n"," 'Loss/total_loss': 0.7575848,\n"," 'learning_rate': 0.53333205}\n","INFO:tensorflow:Step 1300 per-step time 0.274s\n","I0509 01:52:50.037307 140614079854400 model_lib_v2.py:705] Step 1300 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.30666864,\n"," 'Loss/localization_loss': 0.19101076,\n"," 'Loss/regularization_loss': 0.17939681,\n"," 'Loss/total_loss': 0.6770762,\n"," 'learning_rate': 0.56666553}\n","I0509 01:52:50.037660 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.30666864,\n"," 'Loss/localization_loss': 0.19101076,\n"," 'Loss/regularization_loss': 0.17939681,\n"," 'Loss/total_loss': 0.6770762,\n"," 'learning_rate': 0.56666553}\n","INFO:tensorflow:Step 1400 per-step time 0.271s\n","I0509 01:53:17.175348 140614079854400 model_lib_v2.py:705] Step 1400 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2773459,\n"," 'Loss/localization_loss': 0.18876883,\n"," 'Loss/regularization_loss': 0.18467501,\n"," 'Loss/total_loss': 0.65078974,\n"," 'learning_rate': 0.599999}\n","I0509 01:53:17.175795 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.2773459,\n"," 'Loss/localization_loss': 0.18876883,\n"," 'Loss/regularization_loss': 0.18467501,\n"," 'Loss/total_loss': 0.65078974,\n"," 'learning_rate': 0.599999}\n","INFO:tensorflow:Step 1500 per-step time 0.273s\n","I0509 01:53:44.512556 140614079854400 model_lib_v2.py:705] Step 1500 per-step time 0.273s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2964195,\n"," 'Loss/localization_loss': 0.17731784,\n"," 'Loss/regularization_loss': 0.19585131,\n"," 'Loss/total_loss': 0.6695887,\n"," 'learning_rate': 0.6333325}\n","I0509 01:53:44.512924 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.2964195,\n"," 'Loss/localization_loss': 0.17731784,\n"," 'Loss/regularization_loss': 0.19585131,\n"," 'Loss/total_loss': 0.6695887,\n"," 'learning_rate': 0.6333325}\n","INFO:tensorflow:Step 1600 per-step time 0.273s\n","I0509 01:54:11.770647 140614079854400 model_lib_v2.py:705] Step 1600 per-step time 0.273s\n","INFO:tensorflow:{'Loss/classification_loss': 0.23881924,\n"," 'Loss/localization_loss': 0.12650868,\n"," 'Loss/regularization_loss': 0.20117891,\n"," 'Loss/total_loss': 0.56650686,\n"," 'learning_rate': 0.66666603}\n","I0509 01:54:11.771139 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.23881924,\n"," 'Loss/localization_loss': 0.12650868,\n"," 'Loss/regularization_loss': 0.20117891,\n"," 'Loss/total_loss': 0.56650686,\n"," 'learning_rate': 0.66666603}\n","INFO:tensorflow:Step 1700 per-step time 0.271s\n","I0509 01:54:38.848061 140614079854400 model_lib_v2.py:705] Step 1700 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.41312417,\n"," 'Loss/localization_loss': 0.20373102,\n"," 'Loss/regularization_loss': 0.22323807,\n"," 'Loss/total_loss': 0.84009326,\n"," 'learning_rate': 0.6999995}\n","I0509 01:54:38.848469 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.41312417,\n"," 'Loss/localization_loss': 0.20373102,\n"," 'Loss/regularization_loss': 0.22323807,\n"," 'Loss/total_loss': 0.84009326,\n"," 'learning_rate': 0.6999995}\n","INFO:tensorflow:Step 1800 per-step time 0.274s\n","I0509 01:55:06.232657 140614079854400 model_lib_v2.py:705] Step 1800 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4963128,\n"," 'Loss/localization_loss': 0.2656864,\n"," 'Loss/regularization_loss': 0.23358479,\n"," 'Loss/total_loss': 0.995584,\n"," 'learning_rate': 0.733333}\n","I0509 01:55:06.233050 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.4963128,\n"," 'Loss/localization_loss': 0.2656864,\n"," 'Loss/regularization_loss': 0.23358479,\n"," 'Loss/total_loss': 0.995584,\n"," 'learning_rate': 0.733333}\n","INFO:tensorflow:Step 1900 per-step time 0.274s\n","I0509 01:55:33.589781 140614079854400 model_lib_v2.py:705] Step 1900 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.35593638,\n"," 'Loss/localization_loss': 0.19743358,\n"," 'Loss/regularization_loss': 0.23816413,\n"," 'Loss/total_loss': 0.79153407,\n"," 'learning_rate': 0.76666653}\n","I0509 01:55:33.590180 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.35593638,\n"," 'Loss/localization_loss': 0.19743358,\n"," 'Loss/regularization_loss': 0.23816413,\n"," 'Loss/total_loss': 0.79153407,\n"," 'learning_rate': 0.76666653}\n","INFO:tensorflow:Step 2000 per-step time 0.271s\n","I0509 01:56:00.635329 140614079854400 model_lib_v2.py:705] Step 2000 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.2946934,\n"," 'Loss/localization_loss': 0.15790409,\n"," 'Loss/regularization_loss': 0.2400905,\n"," 'Loss/total_loss': 0.692688,\n"," 'learning_rate': 0.8}\n","I0509 01:56:00.635666 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.2946934,\n"," 'Loss/localization_loss': 0.15790409,\n"," 'Loss/regularization_loss': 0.2400905,\n"," 'Loss/total_loss': 0.692688,\n"," 'learning_rate': 0.8}\n","INFO:tensorflow:Step 2100 per-step time 0.283s\n","I0509 01:56:28.976461 140614079854400 model_lib_v2.py:705] Step 2100 per-step time 0.283s\n","INFO:tensorflow:{'Loss/classification_loss': 0.8604606,\n"," 'Loss/localization_loss': 0.5126336,\n"," 'Loss/regularization_loss': 0.4277932,\n"," 'Loss/total_loss': 1.8008873,\n"," 'learning_rate': 0.7996916}\n","I0509 01:56:28.977810 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.8604606,\n"," 'Loss/localization_loss': 0.5126336,\n"," 'Loss/regularization_loss': 0.4277932,\n"," 'Loss/total_loss': 1.8008873,\n"," 'learning_rate': 0.7996916}\n","INFO:tensorflow:Step 2200 per-step time 0.275s\n","I0509 01:56:56.451658 140614079854400 model_lib_v2.py:705] Step 2200 per-step time 0.275s\n","INFO:tensorflow:{'Loss/classification_loss': 0.7468306,\n"," 'Loss/localization_loss': 0.45982277,\n"," 'Loss/regularization_loss': 0.46453306,\n"," 'Loss/total_loss': 1.6711864,\n"," 'learning_rate': 0.7987669}\n","I0509 01:56:56.452011 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.7468306,\n"," 'Loss/localization_loss': 0.45982277,\n"," 'Loss/regularization_loss': 0.46453306,\n"," 'Loss/total_loss': 1.6711864,\n"," 'learning_rate': 0.7987669}\n","INFO:tensorflow:Step 2300 per-step time 0.269s\n","I0509 01:57:23.351431 140614079854400 model_lib_v2.py:705] Step 2300 per-step time 0.269s\n","INFO:tensorflow:{'Loss/classification_loss': 0.543446,\n"," 'Loss/localization_loss': 0.3401956,\n"," 'Loss/regularization_loss': 0.44942054,\n"," 'Loss/total_loss': 1.3330622,\n"," 'learning_rate': 0.7972274}\n","I0509 01:57:23.351837 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.543446,\n"," 'Loss/localization_loss': 0.3401956,\n"," 'Loss/regularization_loss': 0.44942054,\n"," 'Loss/total_loss': 1.3330622,\n"," 'learning_rate': 0.7972274}\n","INFO:tensorflow:Step 2400 per-step time 0.274s\n","I0509 01:57:50.757587 140614079854400 model_lib_v2.py:705] Step 2400 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5514605,\n"," 'Loss/localization_loss': 0.25618023,\n"," 'Loss/regularization_loss': 0.4304002,\n"," 'Loss/total_loss': 1.2380409,\n"," 'learning_rate': 0.79507536}\n","I0509 01:57:50.758510 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.5514605,\n"," 'Loss/localization_loss': 0.25618023,\n"," 'Loss/regularization_loss': 0.4304002,\n"," 'Loss/total_loss': 1.2380409,\n"," 'learning_rate': 0.79507536}\n","INFO:tensorflow:Step 2500 per-step time 0.271s\n","I0509 01:58:17.822979 140614079854400 model_lib_v2.py:705] Step 2500 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5339043,\n"," 'Loss/localization_loss': 0.32067975,\n"," 'Loss/regularization_loss': 0.43001673,\n"," 'Loss/total_loss': 1.2846009,\n"," 'learning_rate': 0.7923141}\n","I0509 01:58:17.823358 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.5339043,\n"," 'Loss/localization_loss': 0.32067975,\n"," 'Loss/regularization_loss': 0.43001673,\n"," 'Loss/total_loss': 1.2846009,\n"," 'learning_rate': 0.7923141}\n","INFO:tensorflow:Step 2600 per-step time 0.268s\n","I0509 01:58:44.580468 140614079854400 model_lib_v2.py:705] Step 2600 per-step time 0.268s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5744674,\n"," 'Loss/localization_loss': 0.32445508,\n"," 'Loss/regularization_loss': 0.426252,\n"," 'Loss/total_loss': 1.3251746,\n"," 'learning_rate': 0.788948}\n","I0509 01:58:44.580835 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.5744674,\n"," 'Loss/localization_loss': 0.32445508,\n"," 'Loss/regularization_loss': 0.426252,\n"," 'Loss/total_loss': 1.3251746,\n"," 'learning_rate': 0.788948}\n","INFO:tensorflow:Step 2700 per-step time 0.273s\n","I0509 01:59:11.840900 140614079854400 model_lib_v2.py:705] Step 2700 per-step time 0.273s\n","INFO:tensorflow:{'Loss/classification_loss': 0.5074701,\n"," 'Loss/localization_loss': 0.26988596,\n"," 'Loss/regularization_loss': 0.48611093,\n"," 'Loss/total_loss': 1.263467,\n"," 'learning_rate': 0.78498214}\n","I0509 01:59:11.841483 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.5074701,\n"," 'Loss/localization_loss': 0.26988596,\n"," 'Loss/regularization_loss': 0.48611093,\n"," 'Loss/total_loss': 1.263467,\n"," 'learning_rate': 0.78498214}\n","INFO:tensorflow:Step 2800 per-step time 0.272s\n","I0509 01:59:39.036552 140614079854400 model_lib_v2.py:705] Step 2800 per-step time 0.272s\n","INFO:tensorflow:{'Loss/classification_loss': 0.66660553,\n"," 'Loss/localization_loss': 0.31914413,\n"," 'Loss/regularization_loss': 0.46860132,\n"," 'Loss/total_loss': 1.454351,\n"," 'learning_rate': 0.7804226}\n","I0509 01:59:39.036955 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.66660553,\n"," 'Loss/localization_loss': 0.31914413,\n"," 'Loss/regularization_loss': 0.46860132,\n"," 'Loss/total_loss': 1.454351,\n"," 'learning_rate': 0.7804226}\n","INFO:tensorflow:Step 2900 per-step time 0.268s\n","I0509 02:00:05.839469 140614079854400 model_lib_v2.py:705] Step 2900 per-step time 0.268s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4352339,\n"," 'Loss/localization_loss': 0.26635858,\n"," 'Loss/regularization_loss': 0.45004022,\n"," 'Loss/total_loss': 1.1516327,\n"," 'learning_rate': 0.7752766}\n","I0509 02:00:05.839895 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.4352339,\n"," 'Loss/localization_loss': 0.26635858,\n"," 'Loss/regularization_loss': 0.45004022,\n"," 'Loss/total_loss': 1.1516327,\n"," 'learning_rate': 0.7752766}\n","INFO:tensorflow:Step 3000 per-step time 0.272s\n","I0509 02:00:33.011604 140614079854400 model_lib_v2.py:705] Step 3000 per-step time 0.272s\n","INFO:tensorflow:{'Loss/classification_loss': 0.400211,\n"," 'Loss/localization_loss': 0.27692598,\n"," 'Loss/regularization_loss': 0.4317833,\n"," 'Loss/total_loss': 1.1089203,\n"," 'learning_rate': 0.7695519}\n","I0509 02:00:33.011987 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.400211,\n"," 'Loss/localization_loss': 0.27692598,\n"," 'Loss/regularization_loss': 0.4317833,\n"," 'Loss/total_loss': 1.1089203,\n"," 'learning_rate': 0.7695519}\n","INFO:tensorflow:Step 3100 per-step time 0.302s\n","I0509 02:01:03.242179 140614079854400 model_lib_v2.py:705] Step 3100 per-step time 0.302s\n","INFO:tensorflow:{'Loss/classification_loss': 0.36073738,\n"," 'Loss/localization_loss': 0.17708197,\n"," 'Loss/regularization_loss': 0.415391,\n"," 'Loss/total_loss': 0.95321035,\n"," 'learning_rate': 0.76325727}\n","I0509 02:01:03.242604 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.36073738,\n"," 'Loss/localization_loss': 0.17708197,\n"," 'Loss/regularization_loss': 0.415391,\n"," 'Loss/total_loss': 0.95321035,\n"," 'learning_rate': 0.76325727}\n","INFO:tensorflow:Step 3200 per-step time 0.271s\n","I0509 02:01:30.401834 140614079854400 model_lib_v2.py:705] Step 3200 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.41625828,\n"," 'Loss/localization_loss': 0.21130648,\n"," 'Loss/regularization_loss': 0.40017593,\n"," 'Loss/total_loss': 1.0277407,\n"," 'learning_rate': 0.7564026}\n","I0509 02:01:30.404747 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.41625828,\n"," 'Loss/localization_loss': 0.21130648,\n"," 'Loss/regularization_loss': 0.40017593,\n"," 'Loss/total_loss': 1.0277407,\n"," 'learning_rate': 0.7564026}\n","INFO:tensorflow:Step 3300 per-step time 0.274s\n","I0509 02:01:57.793470 140614079854400 model_lib_v2.py:705] Step 3300 per-step time 0.274s\n","INFO:tensorflow:{'Loss/classification_loss': 0.304883,\n"," 'Loss/localization_loss': 0.16182798,\n"," 'Loss/regularization_loss': 0.38594344,\n"," 'Loss/total_loss': 0.85265446,\n"," 'learning_rate': 0.7489984}\n","I0509 02:01:57.793894 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.304883,\n"," 'Loss/localization_loss': 0.16182798,\n"," 'Loss/regularization_loss': 0.38594344,\n"," 'Loss/total_loss': 0.85265446,\n"," 'learning_rate': 0.7489984}\n","INFO:tensorflow:Step 3400 per-step time 0.273s\n","I0509 02:02:25.040326 140614079854400 model_lib_v2.py:705] Step 3400 per-step time 0.273s\n","INFO:tensorflow:{'Loss/classification_loss': 0.4216337,\n"," 'Loss/localization_loss': 0.20477763,\n"," 'Loss/regularization_loss': 0.37350908,\n"," 'Loss/total_loss': 0.99992037,\n"," 'learning_rate': 0.7410561}\n","I0509 02:02:25.040729 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.4216337,\n"," 'Loss/localization_loss': 0.20477763,\n"," 'Loss/regularization_loss': 0.37350908,\n"," 'Loss/total_loss': 0.99992037,\n"," 'learning_rate': 0.7410561}\n","INFO:tensorflow:Step 3500 per-step time 0.271s\n","I0509 02:02:52.136532 140614079854400 model_lib_v2.py:705] Step 3500 per-step time 0.271s\n","INFO:tensorflow:{'Loss/classification_loss': 0.35224962,\n"," 'Loss/localization_loss': 0.16453522,\n"," 'Loss/regularization_loss': 0.36250773,\n"," 'Loss/total_loss': 0.8792926,\n"," 'learning_rate': 0.7325879}\n","I0509 02:02:52.137149 140614079854400 model_lib_v2.py:708] {'Loss/classification_loss': 0.35224962,\n"," 'Loss/localization_loss': 0.16453522,\n"," 'Loss/regularization_loss': 0.36250773,\n"," 'Loss/total_loss': 0.8792926,\n"," 'learning_rate': 0.7325879}\n"]}],"source":["%cd {repo_dir_path}\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uL0G8Spi8BbG"},"outputs":[],"source":["# Check the generated files\n","!ls -lrt {model_dir}"]},{"cell_type":"markdown","metadata":{"id":"mLCJsRZF8Dc5"},"source":["Evaluation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWVY9q-J8EqO"},"outputs":[],"source":["%cd {repo_dir_path}\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --checkpoint_dir={model_dir} \\\n","    --eval_timeout=60"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuW6q8p28H5G"},"outputs":[],"source":["# Check the generated files\n","!ls -lrt {model_dir}"]},{"cell_type":"markdown","metadata":{"id":"UhHp2VvX8Qhu"},"source":["Export the output model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68poSBvf8SEu"},"outputs":[],"source":["%cd {repo_dir_path}\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","    --input_type image_tensor \\\n","    --pipeline_config_path {pipeline_fname} \\\n","    --trained_checkpoint_dir {model_dir} \\\n","    --output_directory {output_dir}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0BBFIpf28XUH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683762335112,"user_tz":-480,"elapsed":9,"user":{"displayName":"Winston A","userId":"03807270308659421041"}},"outputId":"3cd490f3-8633-4794-ad1e-a428f9b80a4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{output_dir}\n","ls: cannot access '{output_dir}': No such file or directory\n"]}],"source":["# Check the output files\n","!echo {output_dir}\n","!ls -lsr {output_dir}"]},{"cell_type":"markdown","metadata":{"id":"X8ea--zV86eo"},"source":["ARCHIVE THE OUTPUT DIRECTORY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0EWkQuO8-h9"},"outputs":[],"source":["%cd {repo_dir_path}\n","!tar zcvf trained_model.tar.gz {output_dir}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGIRGGw59CSg","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"error","timestamp":1683762355647,"user_tz":-480,"elapsed":977,"user":{"displayName":"Winston A","userId":"03807270308659421041"}},"outputId":"7e05d44b-86ce-464e-892d-fce7e9e9b5cc"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-619757dbcaa5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained_model.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: trained_model.tar.gz"]}],"source":["from google.colab import files\n","files.download('trained_model.tar.gz')"]},{"cell_type":"markdown","metadata":{"id":"HHjXa16m9Dh-"},"source":["Prediction\n"]},{"cell_type":"markdown","source":["Find image files"],"metadata":{"id":"WlaP5_q4D1eV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_1NTqpc9G7G"},"outputs":[],"source":["import os\n","\n","# Use images in test dir (update this if you have other images for inference)\n","IMAGE_DIR = os.path.join(repo_dir_path, \"images\", \"test\")\n","IMAGE_PATHS = []\n","\n","for file in os.listdir(IMAGE_DIR):\n","    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n","        IMAGE_PATHS.append(os.path.join(IMAGE_DIR, file))\n","\n","IMAGE_PATHS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yx2EaDGk9O9e","colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"status":"error","timestamp":1683762418677,"user_tz":-480,"elapsed":2662,"user":{"displayName":"Winston A","userId":"03807270308659421041"}},"outputId":"ffb966cd-9caf-4328-b273-f29f5800b56b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-65583ca833a9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;31m# Added as colab instance often crash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["%cd /content\n","\n","import time\n","import tensorflow as tf # Added as colab instance often crash\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","# Label Map path\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","# Saved model path\n","PATH_TO_SAVED_MODEL = os.path.join(output_dir, \"saved_model\")\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# Load saved model and build the detection function\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))\n","\n","# Set category index\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","                                                                    use_display_name=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2NkgCNZB9TNZ"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","# This is required to display the images.\n","%matplotlib inline \n","\n","for image_path in IMAGE_PATHS:\n","\n","    print('Running inference for {}... '.format(image_path), end='')\n","\n","    # Puts image into numpy array to feed into tensorflow graph.\n","    # Note that by convention we put it into a numpy array with shape\n","    #   (height, width, channels), where channels=3 for RGB.\n","    image_np = np.array(Image.open(image_path))\n","\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","\n","    # input_tensor = np.expand_dims(image_np, 0)\n","    detections = detect_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                   for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=20,\n","          min_score_thresh=.50,\n","          agnostic_mode=False)\n","\n","    plt.figure(figsize = (12,8))\n","    plt.imshow(image_np_with_detections)\n","    print('Done')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1GLVZBEU9lXKukUHaLTS4nNSd274qx6Vn","timestamp":1683771320842}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}